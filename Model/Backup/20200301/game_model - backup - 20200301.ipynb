{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "tie11\n",
      "win60\n",
      "loss11\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win59\n",
      "loss14\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0290, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win59\n",
      "loss14\n",
      "tensor(0.0289, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win60\n",
      "loss13\n",
      "tensor(0.0287, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tie12\n",
      "win60\n",
      "loss10\n"
     ]
    }
   ],
   "source": [
    "#to explore: the step make game lose = score should be lower? like: [-1,-1,0,0,1,0,0,0,0], next step should be 2, otherwise will lose for sure.\n",
    "#to explore: should it be another model to explore all possible fastest lose situation? Or it is just put some noise will resolve\n",
    "#to explore: add some noise into input/ output during training\n",
    "#to explore: remove duplication on training data & score\n",
    "#resolved - to explore: seperate game engine & cnn into seperate py file\n",
    "#to explore: what should be a better DQ_ratio?\n",
    "#to explore: create a chat to show training journey in a pic.\n",
    "#to explore: Should that be using all pre-training data always everytime train the model??\n",
    "#to explore: some scenarios AI always loss, may due to no noise on inout\n",
    "#to explore: if j % 2 == 0:latest version, here needs to be re-visit, may impact final result.\n",
    "#to explore: \n",
    "#to explore: \n",
    "\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "input_file_path = '../Data/training_data_input.csv'\n",
    "score_file_path = '../Data/training_data_score.csv'\n",
    "input_file_path_initiate = '../Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = '../Data/training_data_score_initiate.csv'\n",
    "training_file_path = '../Data/training_data.csv'\n",
    "\n",
    "#feel like this part can be improved in a way.\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "def training_model():\n",
    "    \n",
    "    #1 means there is an existing model saved\n",
    "    #0 means there is no model saved in folder\n",
    "    \n",
    "    if os.path.isfile(file_name_model_latest_version):\n",
    "        indicator = 1\n",
    "        input_data = data_input(input_file_path)\n",
    "        score_data = data_input(score_file_path)\n",
    "    else:\n",
    "        indicator = 0\n",
    "        input_data = data_input(input_file_path_initiate)\n",
    "        score_data = data_input(score_file_path_initiate)\n",
    "        #give some initial value is another option\n",
    "        #input_data = torch.tensor([0,0,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "        #score_data = torch.tensor([0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11], dtype=torch.float)\n",
    "\n",
    "    input = input_data\n",
    "    target = score_data\n",
    "    # create your optimizer\n",
    "    net = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "    if indicator == 1:\n",
    "        state_dict_last_version = torch.load('model_latest_version.pt')['state_dict']\n",
    "        net.load_state_dict(state_dict_last_version)\n",
    "        #to explore function to load optimizer from existing model\n",
    "        #optimizer.load_state_dict(torch.load('model_latest_version.pt')['optimizer'])\n",
    "    # in your training loop:\n",
    "    for i in range(1,3000):\n",
    "        #to explore a batch job for training\n",
    "        #to explore how to save best performance model during 6000 epochs\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % 999 == 0:\n",
    "            print(loss)\n",
    "        optimizer.step()    # Does the update\n",
    "    \n",
    "    if indicator == 1:\n",
    "        copyfile(file_name_model_latest_version, file_name_model_last_version)\n",
    "    else:\n",
    "        torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_last_version)\n",
    "    torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_latest_version)\n",
    "\n",
    "\n",
    "def main():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    \n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    training_data = data_input(training_file_path)\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    #data_original = [0,0,0,0,0,0,0,0,0]\n",
    "    #torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "    for x in range(0,82):\n",
    "        torch_tensor = training_data[x].clone()\n",
    "        for j in range(0,9):\n",
    "            if j == 0:\n",
    "                ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "                game_a = game_agent(torch_tensor,0)\n",
    "                if game_a.verify_result() == True:\n",
    "                    print('not valid input')\n",
    "                    break\n",
    "                elif 0 not in torch_tensor:\n",
    "                    print('input tie & with 9 value')\n",
    "                    break\n",
    "                else:\n",
    "                    #initial\n",
    "                    input_status = []\n",
    "                    next_action_taken = []\n",
    "                    score = []\n",
    "                    #score = torch.zeros(9)\n",
    "            torch_tensor_saved = torch_tensor.clone()\n",
    "            input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "            #predict\n",
    "            if j % 2 == 0:\n",
    "                next_vision = model_latest_version(torch_tensor)\n",
    "            else:\n",
    "                next_vision = model_last_version(torch_tensor)\n",
    "\n",
    "            #print(next_vision)\n",
    "            current_score = torch.zeros(9)\n",
    "            #comprehance predict result to make impossible option as '-1'\n",
    "            for k in range(0,9):\n",
    "                if torch_tensor[k] != 0:\n",
    "                    next_vision[k] = -1.1\n",
    "                    current_score[k] = -1.1\n",
    "            next_step = next_vision.argmax()\n",
    "            #save next action\n",
    "\n",
    "            next_action_taken.append(next_step.cpu().numpy())\n",
    "            score.append(current_score.cpu().numpy())\n",
    "            #generate result\n",
    "            torch_tensor[next_step] = 1\n",
    "            game_a = game_agent(torch_tensor,0)\n",
    "            # varify status of result\n",
    "            if game_a.verify_result() == True:\n",
    "                #print(game_a.verify_result())\n",
    "                #calculate DQ\n",
    "                if j % 2 == 0:\n",
    "                    win += 1\n",
    "                else:\n",
    "                    loss += 1\n",
    "                #print('finished')\n",
    "                ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "                current_final_score = 1\n",
    "                #update score\n",
    "                for k in range(0, len(next_action_taken)):\n",
    "                    score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "\n",
    "                #####################break for what?\n",
    "                break\n",
    "            else:\n",
    "                if 0 not in torch_tensor:\n",
    "                    #print('tie')\n",
    "                    tie = tie + 1\n",
    "                    break\n",
    "                else:\n",
    "                    #generate next input\n",
    "                    torch_tensor = torch_tensor * -1\n",
    "        input_status_df = pd.DataFrame(input_status)\n",
    "        input_status_df.to_csv('../Data/training_data_input.csv', index=False, mode='a', header=False)\n",
    "        next_action_taken_df = pd.DataFrame(next_action_taken)\n",
    "        next_action_taken_df.to_csv('../Data/training_data_next_action_taken.csv', index=False, mode='a', header=False)\n",
    "        score_df = pd.DataFrame(score)\n",
    "        score_df.to_csv('../Data/training_data_score.csv', index=False, mode='a', header=False)\n",
    "    print(\"tie\" + str(tie))\n",
    "    print(\"win\" + str(win))\n",
    "    print(\"loss\" + str(loss))\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    button = 1\n",
    "    if button == 1:\n",
    "        for loops in range(0,5):\n",
    "            training_model()\n",
    "            main()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_vision\n",
      "tensor([-1.0229, -1.0290, -0.0322, -0.0310, -1.1401, -0.0284,  0.0648,  0.0527,\n",
      "        -0.0791], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(6)\n",
      "tie0\n",
      "win0\n",
      "loss0\n"
     ]
    }
   ],
   "source": [
    "#to explore: a UI for game - it can be a excel or something.\n",
    "#defect: win, it shows loss as there is no goto\n",
    "\n",
    "\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "input_file_path = '../Data/training_data_input.csv'\n",
    "score_file_path = '../Data/training_data_score.csv'\n",
    "input_file_path_initiate = '../Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = '../Data/training_data_score_initiate.csv'\n",
    "training_file_path = '../Data/training_data.csv'\n",
    "\n",
    "#feel like this part can be improved in a way.\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "def main():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    \n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    training_data = data_input(training_file_path)\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    data_original = [-1,-1,0,0,1,0,0,0,0]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "\n",
    "    ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    if game_a.verify_result() == True:\n",
    "        print('not valid input')\n",
    "    elif 0 not in torch_tensor:\n",
    "        print('input tie & with 9 value')\n",
    "    else:\n",
    "        #initial\n",
    "        input_status = []\n",
    "        next_action_taken = []\n",
    "        score = []\n",
    "        #score = torch.zeros(9)\n",
    "    torch_tensor_saved = torch_tensor.clone()\n",
    "    input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "    #predict\n",
    "\n",
    "    next_vision = model_latest_version(torch_tensor)\n",
    "\n",
    "    print('next_vision')\n",
    "    print(next_vision)\n",
    "    current_score = torch.zeros(9)\n",
    "    #comprehance predict result to make impossible option as '-1'\n",
    "    for k in range(0,9):\n",
    "        if torch_tensor[k] != 0:\n",
    "            next_vision[k] = -1.1\n",
    "            current_score[k] = -1.1\n",
    "    next_step = next_vision.argmax()\n",
    "    print('next_step')\n",
    "    print(next_step)\n",
    "    #save next action\n",
    "\n",
    "    next_action_taken.append(next_step.cpu().numpy())\n",
    "    score.append(current_score.cpu().numpy())\n",
    "    #generate result\n",
    "    torch_tensor[next_step] = 1\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    # varify status of result\n",
    "    if game_a.verify_result() == True:\n",
    "        #print(game_a.verify_result())\n",
    "        #calculate DQ\n",
    "        win += 1\n",
    "        #print('finished')\n",
    "        ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "        current_final_score = 1\n",
    "        #update score\n",
    "        for k in range(0, len(next_action_taken)):\n",
    "            score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "    else:\n",
    "        if 0 not in torch_tensor:\n",
    "            #print('tie')\n",
    "            tie = tie + 1\n",
    "        else:\n",
    "            #generate next input\n",
    "            torch_tensor = torch_tensor * -1\n",
    "\n",
    "    print(\"tie\" + str(tie))\n",
    "    print(\"win\" + str(win))\n",
    "    print(\"loss\" + str(loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    button = 0\n",
    "    if button == 1:\n",
    "        for loops in range(0,5):\n",
    "            training_model()\n",
    "            main()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, -1, 0, 0, 0, 0, 0, 0]\n",
      "next_vision\n",
      "tensor([-0.0175, -0.0164, -1.1056, -0.0888,  0.0410, -0.0543,  0.0258, -0.0842,\n",
      "        -0.0204], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "['', '', 'o', '', 'x', '', '', '', '']\n",
      "[0, 0, -1, 0, 1, -1, 0, 0, 0]\n",
      "next_vision\n",
      "tensor([-0.0441,  0.0910, -1.0853, -0.0851, -1.0351, -1.0311, -0.0680, -0.0020,\n",
      "         0.2151], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(8)\n",
      "tensor(8)\n",
      "['', '', 'o', '', 'x', 'o', '', '', 'x']\n",
      "[-1, 0, -1, 0, 1, -1, 0, 0, 1]\n",
      "next_vision\n",
      "tensor([-1.0503,  0.0504, -1.1625, -0.2457, -1.0078, -1.1254,  0.0182, -0.1435,\n",
      "        -1.0510], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "['o', 'x', 'o', '', 'x', 'o', '', '', 'x']\n",
      "[-1, 1, -1, 0, 1, -1, 0, -1, 1]\n",
      "next_vision\n",
      "tensor([-0.9203, -1.0883, -1.2302, -0.1177, -1.0750, -1.1266, -0.1854, -0.9711,\n",
      "        -1.0950], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "['o', 'x', 'o', 'x', 'x', 'o', '', 'o', 'x']\n",
      "[-1, 1, -1, 1, 1, -1, -1, -1, 1]\n",
      "input tie & with 9 value\n",
      "next_vision\n",
      "tensor([-1.0262, -1.2315, -1.1904, -1.0430, -1.1049, -0.9629, -1.2042, -1.0498,\n",
      "        -1.0797], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(8)\n",
      "tensor(8)\n",
      "['o', 'x', 'o', 'x', 'x', 'o', 'o', 'o', 'x']\n"
     ]
    }
   ],
   "source": [
    "# an option to let AI do first\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "tie = 0\n",
    "win = 0\n",
    "loss = 0\n",
    "\n",
    "#load model\n",
    "model_last_version = Net()\n",
    "state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "model_last_version.load_state_dict(state_dict_last_version)\n",
    "\n",
    "model_latest_version = Net()\n",
    "state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "\n",
    "\n",
    "def trigger_AI(data_original):\n",
    "    game_result = \"Ongoing..\"\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "    ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    if game_a.verify_result() == True:\n",
    "        print('Win')\n",
    "        game_result = \"Win\"\n",
    "    elif 0 not in torch_tensor:\n",
    "        print('input tie & with 9 value')\n",
    "        game_result = \"input tie & with 9 value\"\n",
    "    else:\n",
    "        #initial\n",
    "        input_status = []\n",
    "        next_action_taken = []\n",
    "        score = []\n",
    "        #score = torch.zeros(9)\n",
    "    #torch_tensor_saved = torch_tensor.clone()\n",
    "    #input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "    #predict\n",
    "\n",
    "    next_vision = model_latest_version(torch_tensor)\n",
    "\n",
    "    print('next_vision')\n",
    "    print(next_vision)\n",
    "    current_score = torch.zeros(9)\n",
    "    #comprehance predict result to make impossible option as '-1'\n",
    "    for k in range(0,9):\n",
    "        if torch_tensor[k] != 0:\n",
    "            next_vision[k] = -1.1\n",
    "            current_score[k] = -1.1\n",
    "    next_step = next_vision.argmax()\n",
    "    print('next_step')\n",
    "    print(next_step)\n",
    "    #save next action\n",
    "\n",
    "    #next_action_taken.append(next_step.cpu().numpy())\n",
    "    #score.append(current_score.cpu().numpy())\n",
    "    #generate result\n",
    "    torch_tensor[next_step] = 1\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    # varify status of result\n",
    "    if game_a.verify_result() == True:\n",
    "        #print(game_a.verify_result())\n",
    "        #calculate DQ\n",
    "        #win += 1\n",
    "        #print('finished')\n",
    "        game_result = 'Loss'\n",
    "        ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "        #update score\n",
    "    else:\n",
    "        if 0 not in torch_tensor:\n",
    "            #print('tie')\n",
    "            game_result = 'tie'\n",
    "            #tie = tie + 1\n",
    "        else:\n",
    "            #generate next input\n",
    "            torch_tensor = torch_tensor * -1\n",
    "    return next_step, game_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "window.title(\"Welcome to Game made by HX\")\n",
    "window.geometry('400x400')\n",
    "lbl = Label(window, text=\"Hello\")\n",
    "\n",
    "\n",
    "data_original = [0,0,0,0,0,0,0,0,0]\n",
    "game_board = ['','','','','','','','','']\n",
    "\n",
    "#lbl.grid(column=0, row=0)\n",
    "#txt = Entry(window,width=10)\n",
    "#txt.grid(column=1, row=0)\n",
    "btn_00_text = StringVar()\n",
    "btn_01_text = StringVar()\n",
    "btn_02_text = StringVar()\n",
    "btn_10_text = StringVar()\n",
    "btn_11_text = StringVar()\n",
    "btn_12_text = StringVar()\n",
    "btn_20_text = StringVar()\n",
    "btn_21_text = StringVar()\n",
    "btn_22_text = StringVar()\n",
    "#\n",
    "\n",
    "\n",
    "def refresh_game_board(data_original):\n",
    "    for i in range(0,9):\n",
    "        if data_original[i] == -1:\n",
    "            game_board[i] = 'o'\n",
    "        elif data_original[i] == 1:\n",
    "            game_board[i] = 'x'\n",
    "        else:\n",
    "            game_board[i] = ''\n",
    "    btn_00_text.set(game_board[0])\n",
    "    btn_01_text.set(game_board[1])\n",
    "    btn_02_text.set(game_board[2])\n",
    "    btn_10_text.set(game_board[3])\n",
    "    btn_11_text.set(game_board[4])\n",
    "    btn_12_text.set(game_board[5])\n",
    "    btn_20_text.set(game_board[6])\n",
    "    btn_21_text.set(game_board[7])\n",
    "    btn_22_text.set(game_board[8])\n",
    "    \n",
    "    \n",
    "\n",
    "def button_00_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_00_text.get() == '':\n",
    "        btn_00_text.set(\"o\")\n",
    "        data_original[0] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "def button_01_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_01_text.get() == '':\n",
    "        btn_01_text.set(\"o\")\n",
    "        data_original[1] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "        \n",
    "def button_02_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_02_text.get() == '':\n",
    "        btn_02_text.set(\"o\")\n",
    "        data_original[2] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_10_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_10_text.get() == '':\n",
    "        btn_10_text.set(\"o\")\n",
    "        data_original[3] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "def button_11_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_11_text.get() == '':\n",
    "        btn_11_text.set(\"o\")\n",
    "        data_original[4] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_12_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_12_text.get() == '':\n",
    "        btn_12_text.set(\"o\")\n",
    "        data_original[5] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_20_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_20_text.get() == '':\n",
    "        btn_20_text.set(\"o\")\n",
    "        data_original[6] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "\n",
    "def button_21_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_21_text.get() == '':\n",
    "        btn_21_text.set(\"o\")\n",
    "        data_original[7] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "        \n",
    "def button_22_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_22_text.get() == '':\n",
    "        btn_22_text.set(\"o\")\n",
    "        data_original[8] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "btn_00 = Button(window, textvariable=btn_00_text, command=button_00_clicked, height = 2, width = 4)\n",
    "btn_00.grid(row=0, column=0)\n",
    "btn_00_text.set('')\n",
    "\n",
    "btn_01 = Button(window, textvariable=btn_01_text, command=button_01_clicked, height = 2, width = 4)\n",
    "btn_01.grid(row=0, column=1)\n",
    "\n",
    "btn_02 = Button(window, textvariable=btn_02_text, command=button_02_clicked, height = 2, width = 4)\n",
    "btn_02.grid(row=0, column=2)\n",
    "\n",
    "btn_10 = Button(window, textvariable=btn_10_text, command=button_10_clicked, height = 2, width = 4)\n",
    "btn_10.grid(row=1, column=0)\n",
    "\n",
    "btn_11 = Button(window, textvariable=btn_11_text, command=button_11_clicked, height = 2, width = 4)\n",
    "btn_11.grid(row=1, column=1)\n",
    "\n",
    "btn_12 = Button(window, textvariable=btn_12_text, command=button_12_clicked, height = 2, width = 4)\n",
    "btn_12.grid(row=1, column=2)\n",
    "\n",
    "btn_20 = Button(window, textvariable=btn_20_text, command=button_20_clicked, height = 2, width = 4)\n",
    "btn_20.grid(row=2, column=0)\n",
    "\n",
    "btn_21 = Button(window, textvariable=btn_21_text, command=button_21_clicked, height = 2, width = 4)\n",
    "btn_21.grid(row=2, column=1)\n",
    "\n",
    "btn_22 = Button(window, textvariable=btn_22_text, command=button_22_clicked, height = 2, width = 4)\n",
    "btn_22.grid(row=2, column=2)\n",
    "\n",
    "lbl = Label(window, text=\"Hello\")\n",
    "lbl.grid(column=4, row=4)\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "def update_btn_text():\n",
    "    btn_text.set(\"b\")\n",
    "\n",
    "btn_text = tk.StringVar()\n",
    "btn = tk.Button(root, textvariable=btn_text, command=update_btn_text)\n",
    "btn_text.set(\"a\")\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
