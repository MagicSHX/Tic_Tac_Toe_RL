{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 1.]])\n",
      "True\n",
      "False\n",
      "tensor(1.) tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.) tensor(0.)\n",
      "tensor(1.) tensor(0.) tensor(1.)\n",
      "tensor(1.) tensor(0.) tensor(1.)\n",
      "tensor(0.) tensor(1.) tensor(0.)\n",
      "tensor(1.) tensor(0.) tensor(1.)\n",
      "tensor(1.) tensor(1.) tensor(1.)\n",
      "1\n",
      "tensor(1.) tensor(1.) tensor(1.)\n",
      "('yesss', tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    data_original = [[1,1,1],[1,1,1],[1,1,1]]\n",
    "    data_original = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "    data_original = [[1,0,1],[0,1,0],[1,0,1]]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    print(torch_tensor)\n",
    "    game_a = game_agent(torch_tensor, 0)\n",
    "    print(game_a.result())\n",
    "    print(verify_3_same_value(0,0,0))\n",
    "    print(game_a.verify_result())\n",
    "\n",
    "class game_agent:\n",
    "    def __init__(self, input_string, status):\n",
    "        self.input_string = input_string\n",
    "        self.status = status\n",
    "        self.verify_Matrix = [[[0,0],[0,1],[0,2]],[[1,0],[1,1],[1,2]],[[2,0],[2,1],[2,2]],[[0,0],[1,0],[2,0]],[[0,1],[1,1],[2,1]],[[0,2],[1,2],[2,2]],[[0,0],[1,1],[2,2]],[[0,2],[1,1],[2,0]]]\n",
    "        self.verify_Matrix = np.array(self.verify_Matrix)\n",
    "    def restart(self):\n",
    "        print(self.input_string)\n",
    "        return('dsff')\n",
    "    def next_action(self):\n",
    "        print('next action')\n",
    "    def result(self):\n",
    "        if self.input_string[1,1] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def verify_result(self):\n",
    "        status = 'no'\n",
    "        for i in range(0,8):\n",
    "            a = self.input_string[self.verify_Matrix[i,0,0],self.verify_Matrix[i,0,1]]\n",
    "            b = self.input_string[self.verify_Matrix[i,1,0],self.verify_Matrix[i,1,1]]\n",
    "            c = self.input_string[self.verify_Matrix[i,2,0],self.verify_Matrix[i,2,1]]\n",
    "            print(a,b,c)\n",
    "            if verify_3_same_value(a,b,c) == True:\n",
    "                print(1)\n",
    "                print(a,b,c)\n",
    "                status = 'yesss'\n",
    "                return status,a\n",
    "                break\n",
    "        return status, 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def verify_3_same_value(a,b,c):\n",
    "    if (a == b) & (b == c) & (a != 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-60d73fdc6e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "Matrix = [[[0,0],[0,1],[0,2]],[[1,0],[1,1],[1,2]],[[2,0],[2,1],[2,2]],[[0,0],[1,0],[2,0]],[[0,1],[1,1],[2,1]],[[0,2],[1,2],[2,2]],[[0,0],[1,1],[2,2]],[[0,2],[1,1],[2,0]]]\n",
    "Matrix(0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-eadfd5946c28>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-eadfd5946c28>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    class RL_network:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def main():\n",
    "    \n",
    "\n",
    "\n",
    "class RL_network:\n",
    "    def __init__(self, ):\n",
    "        \n",
    "\n",
    "if name == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  1.,  0., -1.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.]])\n",
      "tensor(0.1173, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1106, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1048, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0998, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0954, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0915, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0880, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0848, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0820, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0794, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0771, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0750, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0731, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0714, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0698, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0684, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0670, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0658, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0647, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0637, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0627, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0618, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0610, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0603, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0596, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0589, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0583, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0577, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0572, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0563, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0558, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0554, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0550, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0542, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0539, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0536, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0532, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0529, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0524, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0521, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0518, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0516, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0513, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0511, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0508, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0506, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0503, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0501, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0499, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0497, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0494, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0492, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0490, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0488, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0486, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0484, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0481, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0479, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0477, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0475, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0473, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0471, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0469, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0467, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0464, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0462, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0460, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0458, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0456, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0453, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0449, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0447, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0444, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0442, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0440, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0437, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0433, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0430, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0428, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0425, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0423, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0418, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0415, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0413, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0410, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0408, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0402, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0400, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0391, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0388, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0386, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0383, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0377, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0374, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0371, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0365, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0362, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0359, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0356, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0353, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0349, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0346, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0343, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0340, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0336, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0333, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0330, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0326, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0319, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0316, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0313, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0309, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0305, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0298, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0287, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0280, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0273, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0239, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0235, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0231, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0227, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0223, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0220, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0216, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0204, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0197, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0193, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0174, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0171, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0167, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0129, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0120, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0117, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0114, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0111, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0108, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0105, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0034, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0033, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0031, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0029, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0027, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0025, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0024, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0022, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0018, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0011, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0001, grad_fn=<MseLossBackward>)\n",
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[ 0.0243,  0.9834,  0.0144,  0.0040, -0.0113,  0.0026, -0.0053, -0.0141,\n",
      "          0.0153],\n",
      "        [ 0.9852,  0.0109, -0.0083, -0.0072,  0.0091,  0.0016,  0.0016,  0.0097,\n",
      "         -0.0089]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "def main():\n",
    "    file_path = '../Data/training_data.xlsx'\n",
    "    torch_tensor_data_input = data_input(file_path)\n",
    "    input_data = torch_tensor_data_input[:,0:9]\n",
    "    output_data = torch_tensor_data_input[:,9:]\n",
    "    #.resize_(4,1)\n",
    "    net = Net()\n",
    "    input = input_data\n",
    "    target = output_data\n",
    "    # create your optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    # in your training loop:\n",
    "    for i in range(1,3000):\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % 10 == 0:\n",
    "            print(loss)\n",
    "        optimizer.step()    # Does the update\n",
    "    torch.save({'state_dict': net.state_dict()}, 'model.pt')\n",
    "    print(target)\n",
    "    print(output)\n",
    "    #x = torch.ones(1, 9)\n",
    "    #x[0,:] = 0.0\n",
    "    #x[2,1] = 0.0\n",
    "    #print(x)\n",
    "    #print(net(x))\n",
    "    \n",
    "def data_input(file_path):\n",
    "    data_original = pd.read_excel(file_path)\n",
    "    torch_tensor = torch.tensor(data_original.values, dtype=torch.float)\n",
    "    print(torch_tensor)\n",
    "    return torch_tensor\n",
    "    \n",
    "def model_NN():\n",
    "    print('123')\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 27)\n",
    "        self.fc2 = nn.Linear(27, 18)\n",
    "        self.fc3 = nn.Linear(18, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3450, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3398, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3330, grad_fn=<MseLossBackward>)\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "tie\n",
      "tie\n",
      "tie15\n",
      "win33\n",
      "loss34\n",
      "tensor(0.3261, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3196, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3141, grad_fn=<MseLossBackward>)\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie14\n",
      "win47\n",
      "loss21\n",
      "tensor(0.3094, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3054, grad_fn=<MseLossBackward>)\n",
      "tensor(0.3015, grad_fn=<MseLossBackward>)\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie6\n",
      "win44\n",
      "loss32\n",
      "tensor(0.2991, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2942, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2881, grad_fn=<MseLossBackward>)\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie7\n",
      "win52\n",
      "loss23\n",
      "tensor(0.2823, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2728, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2629, grad_fn=<MseLossBackward>)\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "tie\n",
      "tie\n",
      "tie\n",
      "tie\n",
      "tie13\n",
      "win49\n",
      "loss20\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "input_file_path = '../Data/training_data_input.csv'\n",
    "score_file_path = '../Data/training_data_score.csv'\n",
    "input_file_path_initiate = '../Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = '../Data/training_data_score_initiate.csv'\n",
    "training_file_path = '../Data/training_data.csv'\n",
    "\n",
    "#feel like this part can be improved in a way.\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "def training_model():\n",
    "    \n",
    "    #1 means there is an existing model saved\n",
    "    #0 means there is no model saved in folder\n",
    "    \n",
    "    if os.path.isfile(file_name_model_latest_version):\n",
    "        indicator = 1\n",
    "        input_data = data_input(input_file_path)\n",
    "        score_data = data_input(score_file_path)\n",
    "    else:\n",
    "        indicator = 0\n",
    "        input_data = data_input(input_file_path_initiate)\n",
    "        score_data = data_input(score_file_path_initiate)\n",
    "        #give some initial value is another option\n",
    "        #input_data = torch.tensor([0,0,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "        #score_data = torch.tensor([0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11], dtype=torch.float)\n",
    "\n",
    "    input = input_data\n",
    "    target = score_data\n",
    "    # create your optimizer\n",
    "    net = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    if indicator == 1:\n",
    "        state_dict_last_version = torch.load('model_latest_version.pt')['state_dict']\n",
    "        net.load_state_dict(state_dict_last_version)\n",
    "        #to explore function to load optimizer from existing model\n",
    "        #optimizer.load_state_dict(torch.load('model_latest_version.pt')['optimizer'])\n",
    "    # in your training loop:\n",
    "    for i in range(1,3000):\n",
    "        #to explore a batch job for training\n",
    "        #to explore how to save best performance model during 6000 epochs\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % 999 == 0:\n",
    "            print(loss)\n",
    "        optimizer.step()    # Does the update\n",
    "    \n",
    "    if indicator == 1:\n",
    "        copyfile(file_name_model_latest_version, file_name_model_last_version)\n",
    "    else:\n",
    "        torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_last_version)\n",
    "    torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_latest_version)\n",
    "\n",
    "    \n",
    "def data_input(file_path):\n",
    "    #to explore: remove duplicatioin\n",
    "    data_original = pd.read_csv(file_path)\n",
    "    torch_tensor = torch.tensor(data_original.values, dtype=torch.float)\n",
    "    #print(torch_tensor)\n",
    "    return torch_tensor\n",
    "\n",
    "\n",
    "def main():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    \n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    training_data = data_input(training_file_path)\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    #data_original = [0,0,0,0,0,0,0,0,0]\n",
    "    #torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "    for x in range(0,82):\n",
    "        torch_tensor = training_data[x].clone()\n",
    "        for j in range(0,9):\n",
    "            if j == 0:\n",
    "                ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "                game_a = game_agent(torch_tensor,0)\n",
    "                if game_a.verify_result() == True:\n",
    "                    print('not valid input')\n",
    "                    break\n",
    "                elif 0 not in torch_tensor:\n",
    "                    print('input tie & with 9 value')\n",
    "                    break\n",
    "                else:\n",
    "                    #initial\n",
    "                    input_status = []\n",
    "                    next_action_taken = []\n",
    "                    score = []\n",
    "                    #score = torch.zeros(9)\n",
    "            torch_tensor_saved = torch_tensor.clone()\n",
    "            input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "            #print('input_status 1st')\n",
    "            #print(input_status)\n",
    "            #print('not finished')\n",
    "            #predict\n",
    "            \n",
    "            if j % 2 == 0:\n",
    "                next_vision = model_latest_version(torch_tensor)\n",
    "            else:\n",
    "                next_vision = model_last_version(torch_tensor)\n",
    "\n",
    "            #print(next_vision)\n",
    "            current_score = torch.zeros(9)\n",
    "            #comprehance predict result to make impossible option as '-1'\n",
    "            for k in range(0,9):\n",
    "                if torch_tensor[k] != 0:\n",
    "                    next_vision[k] = -1.1\n",
    "                    current_score[k] = -1.1\n",
    "            next_step = next_vision.argmax()\n",
    "            #save next action\n",
    "\n",
    "            next_action_taken.append(next_step.cpu().numpy())\n",
    "            score.append(current_score.cpu().numpy())\n",
    "            #generate result\n",
    "            torch_tensor[next_step] = 1\n",
    "            game_a = game_agent(torch_tensor,0)\n",
    "            # varify status of result\n",
    "            if game_a.verify_result() == True:\n",
    "                #print(game_a.verify_result())\n",
    "                #calculate DQ\n",
    "                if j % 2 == 0:\n",
    "                    win += 1\n",
    "                else:\n",
    "                    loss += 1\n",
    "                print('finished')\n",
    "                ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "                current_final_score = 1\n",
    "                #update score\n",
    "                for k in range(0, len(next_action_taken)):\n",
    "                    #print('score')\n",
    "                    #print (score[-(k+1)])\n",
    "                    #print(input_status[-(k+1)])\n",
    "                    #print(next_action_taken[-(k+1)])\n",
    "                    #print (score[-(k+1)][next_action_taken[-(k+1)]])\n",
    "                    score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "                    #print (score[-(k+1)][next_action_taken[-(k+1)]])\n",
    "                    #print (score[-(k+1)])\n",
    "\n",
    "\n",
    "\n",
    "                #####################break for what?\n",
    "                break\n",
    "            else:\n",
    "                if 0 not in torch_tensor:\n",
    "                    print('tie')\n",
    "                    tie = tie + 1\n",
    "                    break\n",
    "                else:\n",
    "                    #generate next input\n",
    "                    torch_tensor = torch_tensor * -1\n",
    "                #print(next_vision)\n",
    "                #print(torch_tensor)\n",
    "                #print(next_step)\n",
    "                #print(game_a.result())\n",
    "                #print(verify_3_same_value(0,0,0))\n",
    "                #print(game_a.verify_result())\n",
    "        #print('input_status')\n",
    "        #print(input_status)\n",
    "        #print('next_action_taken')\n",
    "        #print(next_action_taken)\n",
    "        #print('score')\n",
    "        #print(score)\n",
    "        #print('end of code' + str(j))\n",
    "        input_status_df = pd.DataFrame(input_status)\n",
    "        input_status_df.to_csv('../Data/training_data_input.csv', index=False, mode='a', header=False)\n",
    "        next_action_taken_df = pd.DataFrame(next_action_taken)\n",
    "        next_action_taken_df.to_csv('../Data/training_data_next_action_taken.csv', index=False, mode='a', header=False)\n",
    "        score_df = pd.DataFrame(score)\n",
    "        score_df.to_csv('../Data/training_data_score.csv', index=False, mode='a', header=False)\n",
    "    print(\"tie\" + str(tie))\n",
    "    print(\"win\" + str(win))\n",
    "    print(\"loss\" + str(loss))\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 27)\n",
    "        self.fc2 = nn.Linear(27, 81)\n",
    "        self.fc3 = nn.Linear(81, 27)\n",
    "        self.fc4 = nn.Linear(27, 18)\n",
    "        self.fc5 = nn.Linear(18, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class game_agent:\n",
    "    def __init__(self, input_string, status):\n",
    "        self.input_string = input_string\n",
    "        self.status = status\n",
    "        self.verify_Matrix = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]]\n",
    "        self.verify_Matrix = np.array(self.verify_Matrix)\n",
    "        #print(self.verify_Matrix.argmax())\n",
    "    def restart(self):\n",
    "        print(self.input_string)\n",
    "        return('dsff')\n",
    "    def next_action(self):\n",
    "        print('next action')\n",
    "    def result(self):\n",
    "        if self.input_string[1,1] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def verify_result(self):\n",
    "        status = False\n",
    "        for i in range(0,8):\n",
    "            a = self.input_string[self.verify_Matrix[i,0]]\n",
    "            b = self.input_string[self.verify_Matrix[i,1]]\n",
    "            c = self.input_string[self.verify_Matrix[i,2]]\n",
    "            #print(a,b,c)\n",
    "            if verify_3_same_value(a,b,c) == True:\n",
    "                #print(1)\n",
    "                #print(a,b,c)\n",
    "                status = True\n",
    "                return status\n",
    "                break\n",
    "        return status\n",
    "def verify_3_same_value(a,b,c):\n",
    "    if (a == b) & (b == c) & (a != 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    button = 1\n",
    "    if button == 1:\n",
    "        for loops in range(0,5):\n",
    "            training_model()\n",
    "            main()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not exist\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "if os.path.isfile('filename.txt'):\n",
    "    print (\"File exist\")\n",
    "else:\n",
    "    print (\"File not exist\")\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "\n",
    "\n",
    "\n",
    "def training_model():\n",
    "    #1 means there is an existing model saved\n",
    "    #0 means there is no model saved in folder\n",
    "    \n",
    "    if os.path.isfile(file_name_model_latest_version):\n",
    "        indicator = 1\n",
    "    else:\n",
    "        indicator = 0\n",
    "    print(indicator)\n",
    "    \n",
    "    \n",
    "    torch.tensor([0,0,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "    torch.tensor([0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1], dtype=torch.float)\n",
    "    \n",
    "training_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_00</th>\n",
       "      <th>x_01</th>\n",
       "      <th>x_02</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>y_00</th>\n",
       "      <th>y_01</th>\n",
       "      <th>y_02</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "      <th>y_20</th>\n",
       "      <th>y_21</th>\n",
       "      <th>y_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_00  x_01  x_02  x_10  x_11  x_12  x_20  x_21  x_22  y_00  y_01  y_02  \\\n",
       "0     1     0     0     0    -1     0     0     0     0     0     1     0   \n",
       "\n",
       "   y_10  y_11  y_12  y_20  y_21  y_22  \n",
       "0     0     0     0     0     0     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = '../Data/training_data.xlsx'\n",
    "data_original = pd.read_excel(file_path)\n",
    "data_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    print(i)\n",
    "data_original = [0,0,0,0,0,0,0,0,0]\n",
    "torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "if 1 not in torch_tensor:\n",
    "    print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
      "        [ 1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -1.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.],\n",
      "        [-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "        [ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.]])\n",
      "\n",
      "tensor([ 0.0526, -1.2260, -0.1329, -1.1898, -1.1591, -0.0295,  0.0585, -0.0502,\n",
      "        -0.0390], grad_fn=<AddBackward0>)\n",
      "sdfdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n",
      "tensor(6)\n",
      "tensor([ 0.0526, -1.1000, -0.1329, -1.1000, -1.1000, -0.0295,  0.0585, -0.0502,\n",
      "        -0.0390], grad_fn=<CopySlices>)\n",
      "tensor([-0.,  1., -0., -1.,  1., -0., -1., -0., -0.])\n",
      "tensor(6)\n",
      "False\n",
      "\n",
      "tensor([ 6.0216e-02, -1.0905e+00,  7.1600e-02, -1.0960e+00, -1.0626e+00,\n",
      "        -3.1796e-02, -9.5932e-01,  4.2330e-05,  8.3804e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "sdfdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n",
      "tensor(8)\n",
      "tensor([ 6.0216e-02, -1.1000e+00,  7.1600e-02, -1.1000e+00, -1.1000e+00,\n",
      "        -3.1796e-02, -1.1000e+00,  4.2330e-05,  8.3804e-02],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0., -1.,  0.,  1., -1.,  0.,  1.,  0., -1.])\n",
      "tensor(8)\n",
      "False\n",
      "\n",
      "tensor([ 0.1193, -1.1760, -0.0796, -1.0297, -1.1760, -0.0559, -1.1213, -0.0773,\n",
      "        -1.1386], grad_fn=<AddBackward0>)\n",
      "sdfdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd\n",
      "tensor(0)\n",
      "True\n",
      "finished\n",
      "input_status\n",
      "[array([ 0., -1.,  0.,  1., -1.,  0.,  0.,  0.,  0.], dtype=float32), array([-0.,  1., -0., -1.,  1., -0., -1., -0., -0.], dtype=float32), array([ 0., -1.,  0.,  1., -1.,  0.,  1.,  0., -1.], dtype=float32)]\n",
      "next_action_taken\n",
      "[array(6, dtype=int64), array(8, dtype=int64), array(0, dtype=int64)]\n",
      "score\n",
      "[array([ 0.  , -1.1 ,  0.  , -1.1 , -1.1 ,  0.  ,  0.64,  0.  ,  0.  ],\n",
      "      dtype=float32), array([ 0. , -1.1,  0. , -1.1, -1.1,  0. , -1.1,  0. , -0.8],\n",
      "      dtype=float32), array([ 1. , -1.1,  0. , -1.1, -1.1,  0. , -1.1,  0. , -1.1],\n",
      "      dtype=float32)]\n",
      "end of code2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "def training_model():\n",
    "    input_file_path = '../Data/training_data_input.csv'\n",
    "    input_data = data_input(input_file_path)\n",
    "    \n",
    "    score_file_path = '../Data/training_data_input.csv'\n",
    "    score_data = data_input(score_file_path)\n",
    "    \n",
    "    #.resize_(4,1)\n",
    "    net = Net()\n",
    "    input = input_data\n",
    "    target = score_data\n",
    "    # create your optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    # in your training loop:\n",
    "    for i in range(1,6000):\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % 100 == 0:\n",
    "            print(loss)\n",
    "        optimizer.step()    # Does the update\n",
    "    \n",
    "    src = 'model_latest_version.pt'\n",
    "    dst = 'model_last_version.pt'\n",
    "    copyfile(src, dst)\n",
    "    torch.save({'state_dict': net.state_dict()}, 'model_latest_version.pt')\n",
    "    #print(target)\n",
    "    #print(output)\n",
    "    #x = torch.ones(1, 9)\n",
    "    #x[0,:] = 0.0\n",
    "    #x[2,1] = 0.0\n",
    "    #print(x)\n",
    "    #print(net(input))\n",
    "    \n",
    "def data_input(file_path):\n",
    "    data_original = pd.read_csv(file_path)\n",
    "    torch_tensor = torch.tensor(data_original.values, dtype=torch.float)\n",
    "    #print(torch_tensor)\n",
    "    return torch_tensor\n",
    "\n",
    "\n",
    "def main():\n",
    "    DQ_ratio = 0.80\n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load('model_last_version.pt')['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load('model_latest_version.pt')['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    \n",
    "    training_file_path = '../Data/training_data.csv'\n",
    "    training_data = data_input(training_file_path)\n",
    "    print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    #data_original = [0,0,0,0,0,0,0,0,0]\n",
    "    data_original = [0,-1,0,1,-1,0,0,0,0]\n",
    "    #data_original = [0,-1,1,0,0,1,0,-1,0]\n",
    "    #data_original = [0,-1,1,0,0,1,0,-1,0]\n",
    "    #data_original = [0,-1,1,0,0,1,0,-1,-1]\n",
    "    #data_original = [1,-1,1,0,0,1,0,-1,-1]\n",
    "    #data_original = [1,-1,1,-1,0,1,0,-1,-1]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "\n",
    "    for j in range(0,9):\n",
    "        if j == 0:\n",
    "            ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "            game_a = game_agent(torch_tensor,0)\n",
    "            if game_a.verify_result() == True:\n",
    "                print('not valid input')\n",
    "                break\n",
    "            elif 0 not in torch_tensor:\n",
    "                print('input tie or with 9 value')\n",
    "                break\n",
    "            else:\n",
    "                #initial\n",
    "                input_status = []\n",
    "                next_action_taken = []\n",
    "                score = []\n",
    "                #score = torch.zeros(9)\n",
    "        torch_tensor_saved = torch_tensor.clone()\n",
    "        input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "        #print('input_status 1st')\n",
    "        #print(input_status)\n",
    "        #print('not finished')\n",
    "        #predict\n",
    "\n",
    "        next_vision = model_latest_version(torch_tensor)\n",
    "\n",
    "        print(\"\")\n",
    "        print(next_vision)\n",
    "        current_score = torch.zeros(9)\n",
    "        #comprehance predict result to make impossible option as '-1'\n",
    "        for k in range(0,9):\n",
    "            if torch_tensor[k] != 0:\n",
    "                next_vision[k] = -1.1\n",
    "                current_score[k] = -1.1\n",
    "        next_step = next_vision.argmax()\n",
    "        #save next action\n",
    "        print('sdfdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd')\n",
    "        print(next_step)\n",
    "        next_action_taken.append(next_step.cpu().numpy())\n",
    "        score.append(current_score.cpu().numpy())\n",
    "        #generate result\n",
    "        torch_tensor[next_step] = 1\n",
    "        game_a = game_agent(torch_tensor,0)\n",
    "        # varify status of result\n",
    "        if game_a.verify_result() == True:\n",
    "            print(game_a.verify_result())\n",
    "            #calculate DQ\n",
    "            print('finished')\n",
    "            ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "            current_final_score = 1\n",
    "            #update score\n",
    "            for k in range(0, len(next_action_taken)):\n",
    "                #print('score')\n",
    "                #print (score[-(k+1)])\n",
    "                #print(input_status[-(k+1)])\n",
    "                #print(next_action_taken[-(k+1)])\n",
    "                #print (score[-(k+1)][next_action_taken[-(k+1)]])\n",
    "                score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "                #print (score[-(k+1)][next_action_taken[-(k+1)]])\n",
    "                #print (score[-(k+1)])\n",
    "\n",
    "\n",
    "\n",
    "            #####################break for what?\n",
    "            break\n",
    "        else:\n",
    "            if 0 not in torch_tensor:\n",
    "                print('tie')\n",
    "                break\n",
    "            else:\n",
    "                #generate next input\n",
    "                torch_tensor = torch_tensor * -1\n",
    "            print(next_vision)\n",
    "            print(torch_tensor)\n",
    "            print(next_step)\n",
    "            #print(game_a.result())\n",
    "            #print(verify_3_same_value(0,0,0))\n",
    "            print(game_a.verify_result())\n",
    "    print('input_status')\n",
    "    print(input_status)\n",
    "    print('next_action_taken')\n",
    "    print(next_action_taken)\n",
    "    print('score')\n",
    "    print(score)\n",
    "    print('end of code' + str(j))\n",
    "    input_status_df = pd.DataFrame(input_status)\n",
    "    input_status_df.to_csv('../Data/training_data_input.csv', index=False, mode='a', header=False)\n",
    "    next_action_taken_df = pd.DataFrame(next_action_taken)\n",
    "    next_action_taken_df.to_csv('../Data/training_data_next_action_taken.csv', index=False, mode='a', header=False)\n",
    "    score_df = pd.DataFrame(score)\n",
    "    score_df.to_csv('../Data/training_data_score.csv', index=False, mode='a', header=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 27)\n",
    "        self.fc2 = nn.Linear(27, 18)\n",
    "        self.fc3 = nn.Linear(18, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class game_agent:\n",
    "    def __init__(self, input_string, status):\n",
    "        self.input_string = input_string\n",
    "        self.status = status\n",
    "        self.verify_Matrix = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]]\n",
    "        self.verify_Matrix = np.array(self.verify_Matrix)\n",
    "        #print(self.verify_Matrix.argmax())\n",
    "    def restart(self):\n",
    "        print(self.input_string)\n",
    "        return('dsff')\n",
    "    def next_action(self):\n",
    "        print('next action')\n",
    "    def result(self):\n",
    "        if self.input_string[1,1] == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def verify_result(self):\n",
    "        status = False\n",
    "        for i in range(0,8):\n",
    "            a = self.input_string[self.verify_Matrix[i,0]]\n",
    "            b = self.input_string[self.verify_Matrix[i,1]]\n",
    "            c = self.input_string[self.verify_Matrix[i,2]]\n",
    "            #print(a,b,c)\n",
    "            if verify_3_same_value(a,b,c) == True:\n",
    "                #print(1)\n",
    "                #print(a,b,c)\n",
    "                status = True\n",
    "                return status\n",
    "                break\n",
    "        return status\n",
    "def verify_3_same_value(a,b,c):\n",
    "    if (a == b) & (b == c) & (a != 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
