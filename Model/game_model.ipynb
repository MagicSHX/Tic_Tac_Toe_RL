{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "tie11\n",
      "win60\n",
      "loss11\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0291, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win59\n",
      "loss14\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0290, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win59\n",
      "loss14\n",
      "tensor(0.0289, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "tie9\n",
      "win60\n",
      "loss13\n",
      "tensor(0.0287, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "tie12\n",
      "win60\n",
      "loss10\n"
     ]
    }
   ],
   "source": [
    "#to explore: the step make game lose = score should be lower? like: [-1,-1,0,0,1,0,0,0,0], next step should be 2, otherwise will lose for sure.\n",
    "#to explore: should it be another model to explore all possible fastest lose situation? Or it is just put some noise will resolve\n",
    "#to explore: add some noise into input/ output during training\n",
    "#to explore: remove duplication on training data & score\n",
    "#resolved - to explore: seperate game engine & cnn into seperate py file\n",
    "#to explore: what should be a better DQ_ratio?\n",
    "#to explore: create a chat to show training journey in a pic.\n",
    "#to explore: Should that be using all pre-training data always everytime train the model??\n",
    "#to explore: some scenarios AI always loss, may due to no noise on inout\n",
    "#to explore: if j % 2 == 0:latest version, here needs to be re-visit, may impact final result.\n",
    "#to explore: \n",
    "#to explore: \n",
    "\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "#import py lib from a different folder: https://www.fir3net.com/Programming/Python/how-do-you-import-a-python-module-from-another-folder.html\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "input_file_path = '../Data/training_data_input.csv'\n",
    "score_file_path = '../Data/training_data_score.csv'\n",
    "input_file_path_initiate = '../Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = '../Data/training_data_score_initiate.csv'\n",
    "training_file_path = '../Data/training_data.csv'\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#to explore: feel like this part can be improved in a way.\n",
    "DQ_ratio = 0.80\n",
    "epcho_no = 3000\n",
    "steps_for_printing_out_loss = 1000\n",
    "\n",
    "def training_model():\n",
    "    \n",
    "    #1 means there is an existing model saved\n",
    "    #0 means there is no model saved in folder\n",
    "    \n",
    "    if os.path.isfile(file_name_model_latest_version):\n",
    "        indicator = 1\n",
    "        input_data = data_input(input_file_path)\n",
    "        score_data = data_input(score_file_path)\n",
    "    else:\n",
    "        indicator = 0\n",
    "        input_data = data_input(input_file_path_initiate)\n",
    "        score_data = data_input(score_file_path_initiate)\n",
    "        #give some initial value is another option\n",
    "        #input_data = torch.tensor([0,0,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "        #score_data = torch.tensor([0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11], dtype=torch.float)\n",
    "\n",
    "    input = input_data\n",
    "    target = score_data\n",
    "    # create your optimizer\n",
    "    net = Net()\n",
    "    #to explore: feel like this part can be improved in a way.\n",
    "    # 5 error functions with explainatioins(5 Regression Loss Functions All Machine Learners Should Know): https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "    # HX: It should be alrighht to use MSE instead of MAE, as there is no outlier inside training data here\n",
    "    criterion = nn.MSELoss()\n",
    "    # to explore: visulize parameter updating process, as well as loss impact.\n",
    "    # optim comparation between: SGD & Adam: https://medium.com/@Biboswan98/optim-adam-vs-optim-sgd-lets-dive-in-8dbf1890fbdc\n",
    "    # Here should use Adam compared with SGD(need to explore other Oprim as well), but learning rate should be setup with some strategy. --------Pending\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "    # to explore: if if indicator == 0, any good start of parameter can be assigned?\n",
    "    if indicator == 1:\n",
    "        state_dict_last_version = torch.load('model_latest_version.pt')['state_dict']\n",
    "        net.load_state_dict(state_dict_last_version)\n",
    "        #to explore function to load optimizer from existing model\n",
    "        #optimizer.load_state_dict(torch.load('model_latest_version.pt')['optimizer'])\n",
    "    # in your training loop:\n",
    "    for i in range(1,epcho_no):\n",
    "        #to explore a batch job for training\n",
    "        #to explore how to save best performance model during 6000 epochs\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output = net(input)\n",
    "        # difference between loss, error,criterion: https://datascience.stackexchange.com/questions/10250/what-is-the-difference-between-objective-error-criterion-cost-loss-fun\n",
    "        # to explore: loss can be optimized as well - Pending\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % (steps_for_printing_out_loss - 1) == 0:\n",
    "            print(loss)\n",
    "        optimizer.step()    # Does the update\n",
    "    \n",
    "    if indicator == 1:\n",
    "        copyfile(file_name_model_latest_version, file_name_model_last_version)\n",
    "    else:\n",
    "        torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_last_version)\n",
    "    torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_latest_version)\n",
    "\n",
    "\n",
    "def main():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    \n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    training_data = data_input(training_file_path)\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    #data_original = [0,0,0,0,0,0,0,0,0]\n",
    "    #torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    #to explore: is that possible to perform below by batch, instead of 1 by 1?\n",
    "    for x in range(0,82):\n",
    "        torch_tensor = training_data[x].clone()\n",
    "        for j in range(0,9):\n",
    "            if j == 0:\n",
    "                ###########another exceptional handling: if input without equal occurance of 1 & -1 - pending for coding\n",
    "                game_a = game_agent(torch_tensor,0)\n",
    "                if game_a.verify_result() == True:\n",
    "                    print('not valid input, as game has been over')\n",
    "                    break\n",
    "                elif 0 not in torch_tensor:\n",
    "                    print('input tie & with 9 value')\n",
    "                    break\n",
    "                else:\n",
    "                    #initial\n",
    "                    input_status = []\n",
    "                    next_action_taken = []\n",
    "                    score = []\n",
    "                    #score = torch.zeros(9)\n",
    "            torch_tensor_saved = torch_tensor.clone()\n",
    "            input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "            #predict\n",
    "            #if j % 2 == 1, it means to let last version take the first action\n",
    "            if j % 2 == 0:\n",
    "                next_vision = model_latest_version(torch_tensor)\n",
    "            else:\n",
    "                next_vision = model_last_version(torch_tensor)\n",
    "\n",
    "            #print(next_vision)\n",
    "            current_score = torch.zeros(9)\n",
    "            #comprehance predict result to make impossible option as '-1'\n",
    "            #here there is a big ?, how to aviod prediction result on position with existing point??\n",
    "            for k in range(0,9):\n",
    "                if torch_tensor[k] != 0:\n",
    "                    next_vision[k] = -1.1\n",
    "                    current_score[k] = -1.1\n",
    "            next_step = next_vision.argmax()\n",
    "            #save next action\n",
    "\n",
    "            next_action_taken.append(next_step.cpu().numpy())\n",
    "            score.append(current_score.cpu().numpy())\n",
    "            #generate result\n",
    "            torch_tensor[next_step] = 1\n",
    "            game_a = game_agent(torch_tensor,0)\n",
    "            # varify status of result\n",
    "            # training data duplication should be avoid somewhere, also some inout, action, and different DQ score????????\n",
    "            if game_a.verify_result() == True:\n",
    "                #print(game_a.verify_result())\n",
    "                #calculate DQ\n",
    "                if j % 2 == 0:\n",
    "                    win += 1\n",
    "                else:\n",
    "                    loss += 1\n",
    "                #print('finished')\n",
    "                ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "                current_final_score = 1\n",
    "                #update score, \n",
    "                #To explore: DQ learning score, any alogrithm wise enhancement can be done??\n",
    "                for k in range(0, len(next_action_taken)):\n",
    "                    score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "\n",
    "                #####################break for what?\n",
    "                break\n",
    "            else:\n",
    "                if 0 not in torch_tensor:\n",
    "                    #print('tie')\n",
    "                    tie = tie + 1\n",
    "                    #any DQ score calculated for tie??????????\n",
    "                    break\n",
    "                else:\n",
    "                    #generate next input\n",
    "                    torch_tensor = torch_tensor * -1\n",
    "        input_status_df = pd.DataFrame(input_status)\n",
    "        input_status_df.to_csv('../Data/training_data_input.csv', index=False, mode='a', header=False)\n",
    "        next_action_taken_df = pd.DataFrame(next_action_taken)\n",
    "        next_action_taken_df.to_csv('../Data/training_data_next_action_taken.csv', index=False, mode='a', header=False)\n",
    "        score_df = pd.DataFrame(score)\n",
    "        score_df.to_csv('../Data/training_data_score.csv', index=False, mode='a', header=False)\n",
    "    print(\"tie\" + str(tie))\n",
    "    print(\"win\" + str(win))\n",
    "    print(\"loss\" + str(loss))\n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    button = 1\n",
    "    if button == 1:\n",
    "        for loops in range(0,5):\n",
    "            training_model()\n",
    "            main()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_vision\n",
      "tensor([-1.0229, -1.0290, -0.0322, -0.0310, -1.1401, -0.0284,  0.0648,  0.0527,\n",
      "        -0.0791], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(6)\n",
      "tie0\n",
      "win0\n",
      "loss0\n"
     ]
    }
   ],
   "source": [
    "#to explore: a UI for game - it can be a excel or something.\n",
    "#defect: win, it shows loss as there is no goto\n",
    "\n",
    "\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "input_file_path = '../Data/training_data_input.csv'\n",
    "score_file_path = '../Data/training_data_score.csv'\n",
    "input_file_path_initiate = '../Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = '../Data/training_data_score_initiate.csv'\n",
    "training_file_path = '../Data/training_data.csv'\n",
    "\n",
    "#feel like this part can be improved in a way.\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "def main():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    \n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    training_data = data_input(training_file_path)\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    data_original = [-1,-1,0,0,1,0,0,0,0]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "\n",
    "    ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    if game_a.verify_result() == True:\n",
    "        print('not valid input')\n",
    "    elif 0 not in torch_tensor:\n",
    "        print('input tie & with 9 value')\n",
    "    else:\n",
    "        #initial\n",
    "        input_status = []\n",
    "        next_action_taken = []\n",
    "        score = []\n",
    "        #score = torch.zeros(9)\n",
    "    torch_tensor_saved = torch_tensor.clone()\n",
    "    input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "    #predict\n",
    "\n",
    "    next_vision = model_latest_version(torch_tensor)\n",
    "\n",
    "    print('next_vision')\n",
    "    print(next_vision)\n",
    "    current_score = torch.zeros(9)\n",
    "    #comprehance predict result to make impossible option as '-1'\n",
    "    for k in range(0,9):\n",
    "        if torch_tensor[k] != 0:\n",
    "            next_vision[k] = -1.1\n",
    "            current_score[k] = -1.1\n",
    "    next_step = next_vision.argmax()\n",
    "    print('next_step')\n",
    "    print(next_step)\n",
    "    #save next action\n",
    "\n",
    "    next_action_taken.append(next_step.cpu().numpy())\n",
    "    score.append(current_score.cpu().numpy())\n",
    "    #generate result\n",
    "    torch_tensor[next_step] = 1\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    # varify status of result\n",
    "    if game_a.verify_result() == True:\n",
    "        #print(game_a.verify_result())\n",
    "        #calculate DQ\n",
    "        win += 1\n",
    "        #print('finished')\n",
    "        ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "        current_final_score = 1\n",
    "        #update score\n",
    "        for k in range(0, len(next_action_taken)):\n",
    "            score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "    else:\n",
    "        if 0 not in torch_tensor:\n",
    "            #print('tie')\n",
    "            tie = tie + 1\n",
    "        else:\n",
    "            #generate next input\n",
    "            torch_tensor = torch_tensor * -1\n",
    "\n",
    "    print(\"tie\" + str(tie))\n",
    "    print(\"win\" + str(win))\n",
    "    print(\"loss\" + str(loss))\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    button = 0\n",
    "    if button == 1:\n",
    "        for loops in range(0,5):\n",
    "            training_model()\n",
    "            main()\n",
    "    else:\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, -1, 0, 0, 0, 0, 0, 0]\n",
      "next_vision\n",
      "tensor([-0.0175, -0.0164, -1.1056, -0.0888,  0.0410, -0.0543,  0.0258, -0.0842,\n",
      "        -0.0204], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "['', '', 'o', '', 'x', '', '', '', '']\n",
      "[0, 0, -1, 0, 1, -1, 0, 0, 0]\n",
      "next_vision\n",
      "tensor([-0.0441,  0.0910, -1.0853, -0.0851, -1.0351, -1.0311, -0.0680, -0.0020,\n",
      "         0.2151], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(8)\n",
      "tensor(8)\n",
      "['', '', 'o', '', 'x', 'o', '', '', 'x']\n",
      "[-1, 0, -1, 0, 1, -1, 0, 0, 1]\n",
      "next_vision\n",
      "tensor([-1.0503,  0.0504, -1.1625, -0.2457, -1.0078, -1.1254,  0.0182, -0.1435,\n",
      "        -1.0510], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "['o', 'x', 'o', '', 'x', 'o', '', '', 'x']\n",
      "[-1, 1, -1, 0, 1, -1, 0, -1, 1]\n",
      "next_vision\n",
      "tensor([-0.9203, -1.0883, -1.2302, -0.1177, -1.0750, -1.1266, -0.1854, -0.9711,\n",
      "        -1.0950], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(3)\n",
      "tensor(3)\n",
      "['o', 'x', 'o', 'x', 'x', 'o', '', 'o', 'x']\n",
      "[-1, 1, -1, 1, 1, -1, -1, -1, 1]\n",
      "input tie & with 9 value\n",
      "next_vision\n",
      "tensor([-1.0262, -1.2315, -1.1904, -1.0430, -1.1049, -0.9629, -1.2042, -1.0498,\n",
      "        -1.0797], grad_fn=<AddBackward0>)\n",
      "next_step\n",
      "tensor(8)\n",
      "tensor(8)\n",
      "['o', 'x', 'o', 'x', 'x', 'o', 'o', 'o', 'x']\n"
     ]
    }
   ],
   "source": [
    "# an option to let AI do first\n",
    "import os.path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "\n",
    "#self created lib in py file format\n",
    "from Game_Agent import game_agent\n",
    "from DL_Network_Model import Net\n",
    "from Funtion_Bank import data_input\n",
    "\n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "file_name_model_latest_version = 'model_latest_version.pt'\n",
    "file_name_model_last_version = 'model_last_version.pt'\n",
    "\n",
    "DQ_ratio = 0.80\n",
    "\n",
    "tie = 0\n",
    "win = 0\n",
    "loss = 0\n",
    "\n",
    "#load model\n",
    "model_last_version = Net()\n",
    "state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "model_last_version.load_state_dict(state_dict_last_version)\n",
    "\n",
    "model_latest_version = Net()\n",
    "state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "\n",
    "\n",
    "def trigger_AI(data_original):\n",
    "    game_result = \"Ongoing..\"\n",
    "    #print(training_data)\n",
    "    \n",
    "    #initiallization\n",
    "    #data_original = [1,0,0,-1,0,0,1,-1,0]\n",
    "    #data_original = [0,1,0,0,0,0,-1,0,0]\n",
    "    #data_original = [-1,1,0,1,1,-1,-1,-1,1]\n",
    "    #data_original = [-1,1,1,1,1,-1,-1,-1,1]\n",
    "    torch_tensor = torch.tensor(data_original, dtype=torch.float)\n",
    "    #print('torch_tensor 1st')\n",
    "    #print(torch_tensor)\n",
    "    \n",
    "    ###########another possible scenario: if input without equal occurance of 1 & -1 - pending for coding\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    if game_a.verify_result() == True:\n",
    "        print('Win')\n",
    "        game_result = \"Win\"\n",
    "    elif 0 not in torch_tensor:\n",
    "        print('input tie & with 9 value')\n",
    "        game_result = \"input tie & with 9 value\"\n",
    "    else:\n",
    "        #initial\n",
    "        input_status = []\n",
    "        next_action_taken = []\n",
    "        score = []\n",
    "        #score = torch.zeros(9)\n",
    "    #torch_tensor_saved = torch_tensor.clone()\n",
    "    #input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "    #predict\n",
    "\n",
    "    next_vision = model_latest_version(torch_tensor)\n",
    "\n",
    "    print('next_vision')\n",
    "    print(next_vision)\n",
    "    current_score = torch.zeros(9)\n",
    "    #comprehance predict result to make impossible option as '-1'\n",
    "    for k in range(0,9):\n",
    "        if torch_tensor[k] != 0:\n",
    "            next_vision[k] = -1.1\n",
    "            current_score[k] = -1.1\n",
    "    next_step = next_vision.argmax()\n",
    "    print('next_step')\n",
    "    print(next_step)\n",
    "    #save next action\n",
    "\n",
    "    #next_action_taken.append(next_step.cpu().numpy())\n",
    "    #score.append(current_score.cpu().numpy())\n",
    "    #generate result\n",
    "    torch_tensor[next_step] = 1\n",
    "    game_a = game_agent(torch_tensor,0)\n",
    "    # varify status of result\n",
    "    if game_a.verify_result() == True:\n",
    "        #print(game_a.verify_result())\n",
    "        #calculate DQ\n",
    "        #win += 1\n",
    "        #print('finished')\n",
    "        game_result = 'Loss'\n",
    "        ############ here as an enhancement on model, it could encourage model for a faster win strategy\n",
    "        #update score\n",
    "    else:\n",
    "        if 0 not in torch_tensor:\n",
    "            #print('tie')\n",
    "            game_result = 'tie'\n",
    "            #tie = tie + 1\n",
    "        else:\n",
    "            #generate next input\n",
    "            torch_tensor = torch_tensor * -1\n",
    "    return next_step, game_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "window.title(\"Welcome to Game made by HX\")\n",
    "window.geometry('400x400')\n",
    "lbl = Label(window, text=\"Hello\")\n",
    "\n",
    "\n",
    "data_original = [0,0,0,0,0,0,0,0,0]\n",
    "game_board = ['','','','','','','','','']\n",
    "\n",
    "#lbl.grid(column=0, row=0)\n",
    "#txt = Entry(window,width=10)\n",
    "#txt.grid(column=1, row=0)\n",
    "btn_00_text = StringVar()\n",
    "btn_01_text = StringVar()\n",
    "btn_02_text = StringVar()\n",
    "btn_10_text = StringVar()\n",
    "btn_11_text = StringVar()\n",
    "btn_12_text = StringVar()\n",
    "btn_20_text = StringVar()\n",
    "btn_21_text = StringVar()\n",
    "btn_22_text = StringVar()\n",
    "#\n",
    "\n",
    "\n",
    "def refresh_game_board(data_original):\n",
    "    for i in range(0,9):\n",
    "        if data_original[i] == -1:\n",
    "            game_board[i] = 'o'\n",
    "        elif data_original[i] == 1:\n",
    "            game_board[i] = 'x'\n",
    "        else:\n",
    "            game_board[i] = ''\n",
    "    btn_00_text.set(game_board[0])\n",
    "    btn_01_text.set(game_board[1])\n",
    "    btn_02_text.set(game_board[2])\n",
    "    btn_10_text.set(game_board[3])\n",
    "    btn_11_text.set(game_board[4])\n",
    "    btn_12_text.set(game_board[5])\n",
    "    btn_20_text.set(game_board[6])\n",
    "    btn_21_text.set(game_board[7])\n",
    "    btn_22_text.set(game_board[8])\n",
    "    \n",
    "    \n",
    "\n",
    "def button_00_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_00_text.get() == '':\n",
    "        btn_00_text.set(\"o\")\n",
    "        data_original[0] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "def button_01_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_01_text.get() == '':\n",
    "        btn_01_text.set(\"o\")\n",
    "        data_original[1] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "        \n",
    "def button_02_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_02_text.get() == '':\n",
    "        btn_02_text.set(\"o\")\n",
    "        data_original[2] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_10_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_10_text.get() == '':\n",
    "        btn_10_text.set(\"o\")\n",
    "        data_original[3] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "def button_11_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_11_text.get() == '':\n",
    "        btn_11_text.set(\"o\")\n",
    "        data_original[4] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_12_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_12_text.get() == '':\n",
    "        btn_12_text.set(\"o\")\n",
    "        data_original[5] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "def button_20_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_20_text.get() == '':\n",
    "        btn_20_text.set(\"o\")\n",
    "        data_original[6] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "\n",
    "\n",
    "\n",
    "def button_21_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_21_text.get() == '':\n",
    "        btn_21_text.set(\"o\")\n",
    "        data_original[7] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "        \n",
    "def button_22_clicked():\n",
    "    #lbl.configure(text=\"Button was clicked !!\")\n",
    "    if btn_22_text.get() == '':\n",
    "        btn_22_text.set(\"o\")\n",
    "        data_original[8] = -1\n",
    "        print(data_original)\n",
    "        next_step, game_result = trigger_AI(data_original)\n",
    "        print(next_step)\n",
    "        data_original[next_step] = 1\n",
    "        #print(data_original)\n",
    "        refresh_game_board(data_original)\n",
    "        print(game_board)\n",
    "        lbl.configure(text= game_result)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "btn_00 = Button(window, textvariable=btn_00_text, command=button_00_clicked, height = 2, width = 4)\n",
    "btn_00.grid(row=0, column=0)\n",
    "btn_00_text.set('')\n",
    "\n",
    "btn_01 = Button(window, textvariable=btn_01_text, command=button_01_clicked, height = 2, width = 4)\n",
    "btn_01.grid(row=0, column=1)\n",
    "\n",
    "btn_02 = Button(window, textvariable=btn_02_text, command=button_02_clicked, height = 2, width = 4)\n",
    "btn_02.grid(row=0, column=2)\n",
    "\n",
    "btn_10 = Button(window, textvariable=btn_10_text, command=button_10_clicked, height = 2, width = 4)\n",
    "btn_10.grid(row=1, column=0)\n",
    "\n",
    "btn_11 = Button(window, textvariable=btn_11_text, command=button_11_clicked, height = 2, width = 4)\n",
    "btn_11.grid(row=1, column=1)\n",
    "\n",
    "btn_12 = Button(window, textvariable=btn_12_text, command=button_12_clicked, height = 2, width = 4)\n",
    "btn_12.grid(row=1, column=2)\n",
    "\n",
    "btn_20 = Button(window, textvariable=btn_20_text, command=button_20_clicked, height = 2, width = 4)\n",
    "btn_20.grid(row=2, column=0)\n",
    "\n",
    "btn_21 = Button(window, textvariable=btn_21_text, command=button_21_clicked, height = 2, width = 4)\n",
    "btn_21.grid(row=2, column=1)\n",
    "\n",
    "btn_22 = Button(window, textvariable=btn_22_text, command=button_22_clicked, height = 2, width = 4)\n",
    "btn_22.grid(row=2, column=2)\n",
    "\n",
    "lbl = Label(window, text=\"Hello\")\n",
    "lbl.grid(column=4, row=4)\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "def update_btn_text():\n",
    "    btn_text.set(\"b\")\n",
    "\n",
    "btn_text = tk.StringVar()\n",
    "btn = tk.Button(root, textvariable=btn_text, command=update_btn_text)\n",
    "btn_text.set(\"a\")\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
