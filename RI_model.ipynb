{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (epoch: 1000): 0.015108448\n",
      "Loss (epoch: 2000): 0.014349725\n",
      "Loss (epoch: 3000): 0.014410454\n",
      "win: 106\n",
      "Loss: 48\n",
      "Tie: 10\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.014300729\n",
      "Loss (epoch: 2000): 0.0135454405\n",
      "Loss (epoch: 3000): 0.013508496\n",
      "win: 108\n",
      "Loss: 45\n",
      "Tie: 11\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.013603855\n",
      "Loss (epoch: 2000): 0.013132577\n",
      "Loss (epoch: 3000): 0.012697116\n",
      "win: 115\n",
      "Loss: 42\n",
      "Tie: 7\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.01332021\n",
      "Loss (epoch: 2000): 0.012273604\n",
      "Loss (epoch: 3000): 0.013424181\n",
      "win: 112\n",
      "Loss: 42\n",
      "Tie: 10\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.01251639\n",
      "Loss (epoch: 2000): 0.012929315\n",
      "Loss (epoch: 3000): 0.011715661\n",
      "win: 110\n",
      "Loss: 44\n",
      "Tie: 10\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.012509066\n",
      "Loss (epoch: 2000): 0.011721402\n",
      "Loss (epoch: 3000): 0.011359464\n",
      "win: 108\n",
      "Loss: 47\n",
      "Tie: 9\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.011424413\n",
      "Loss (epoch: 2000): 0.01182347\n",
      "Loss (epoch: 3000): 0.010969579\n",
      "win: 109\n",
      "Loss: 42\n",
      "Tie: 13\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.011188191\n",
      "Loss (epoch: 2000): 0.010840687\n",
      "Loss (epoch: 3000): 0.01065531\n",
      "win: 110\n",
      "Loss: 35\n",
      "Tie: 19\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.010993247\n",
      "Loss (epoch: 2000): 0.010851433\n",
      "Loss (epoch: 3000): 0.010720279\n",
      "win: 104\n",
      "Loss: 30\n",
      "Tie: 30\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.010548622\n",
      "Loss (epoch: 2000): 0.010756124\n",
      "Loss (epoch: 3000): 0.01024921\n",
      "win: 100\n",
      "Loss: 29\n",
      "Tie: 35\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.010028798\n",
      "Loss (epoch: 2000): 0.009913826\n",
      "Loss (epoch: 3000): 0.0098679345\n",
      "win: 101\n",
      "Loss: 25\n",
      "Tie: 38\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009980068\n",
      "Loss (epoch: 2000): 0.009784216\n",
      "Loss (epoch: 3000): 0.009724975\n",
      "win: 108\n",
      "Loss: 26\n",
      "Tie: 30\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009881735\n",
      "Loss (epoch: 2000): 0.009655868\n",
      "Loss (epoch: 3000): 0.010169438\n",
      "win: 115\n",
      "Loss: 23\n",
      "Tie: 26\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.010268233\n",
      "Loss (epoch: 2000): 0.00948527\n",
      "Loss (epoch: 3000): 0.009850621\n",
      "win: 114\n",
      "Loss: 23\n",
      "Tie: 27\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009286202\n",
      "Loss (epoch: 2000): 0.009683895\n",
      "Loss (epoch: 3000): 0.009255978\n",
      "win: 112\n",
      "Loss: 25\n",
      "Tie: 27\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009379521\n",
      "Loss (epoch: 2000): 0.009609679\n",
      "Loss (epoch: 3000): 0.009196417\n",
      "win: 112\n",
      "Loss: 26\n",
      "Tie: 26\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009089321\n",
      "Loss (epoch: 2000): 0.009161367\n",
      "Loss (epoch: 3000): 0.009161777\n",
      "win: 116\n",
      "Loss: 24\n",
      "Tie: 24\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.009656335\n",
      "Loss (epoch: 2000): 0.008801335\n",
      "Loss (epoch: 3000): 0.008784102\n",
      "win: 112\n",
      "Loss: 22\n",
      "Tie: 30\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.00980192\n",
      "Loss (epoch: 2000): 0.008892075\n",
      "Loss (epoch: 3000): 0.008455291\n",
      "win: 108\n",
      "Loss: 21\n",
      "Tie: 35\n",
      "Not valid start: 0\n",
      "Loss (epoch: 1000): 0.008427591\n",
      "Loss (epoch: 2000): 0.008468189\n",
      "Loss (epoch: 3000): 0.008331114\n",
      "win: 109\n",
      "Loss: 20\n",
      "Tie: 35\n",
      "Not valid start: 0\n"
     ]
    }
   ],
   "source": [
    "#Onging exploration:\n",
    "#to explore: High: create a chat to show training journey in a pic.\n",
    "#to explore: if j % 2 == 0:latest version, here needs to be re-visit, may impact final result.\n",
    "#to explore: if possible to setup parameters under main(), so that from Master control script, Main() can directly called, instead of toggling between scripts.\n",
    "#resolved - to explore: How to ensure AI's prediction is 2 in scenario like: [-1,-1,0,0,1,0,0,0,0]? Otherwise AI will lose immediatelly.\n",
    "#resolved - to explore: should it be another model to explore all possible fastest lose situation? Or it is just put some noise will resolve\n",
    "#to explore: High: add some noise into input/ output during training, so that AI can practice more scenarios. (some scenarios AI always loss)\n",
    "#to explore: High: remove duplication on training data & score\n",
    "#to explore: Ongoing: what should be a better DQ_ratio? Is it possible to be some fucntion instead of a constant value?\n",
    "\n",
    "#lib:\n",
    "import os.path\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "\n",
    "#import py lib from a different folder: https://www.fir3net.com/Programming/Python/how-do-you-import-a-python-module-from-another-folder.html\n",
    "#self created lib in py file format\n",
    "from Model.Game_Agent import game_agent\n",
    "from Model.DL_Network_Model import Net\n",
    "from Model.Funtion_Bank import data_input\n",
    "\n",
    "#file_path_setup:\n",
    "file_name_model_latest_version = 'Model/model_latest_version.pt'\n",
    "file_name_model_last_version = 'Model/model_last_version.pt'\n",
    "input_file_path = 'Data/training_data_input.csv'\n",
    "score_file_path = 'Data/training_data_score.csv'\n",
    "next_action_file_path = 'Data/training_data_next_action_taken.csv'\n",
    "input_file_path_initiate = 'Data/training_data_input_initiate.csv'\n",
    "score_file_path_initiate = 'Data/training_data_score_initiate.csv'\n",
    "training_file_path = 'Data/training_data.csv'\n",
    "\n",
    "#data format setup:\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "#parameter setup:\n",
    "#to explore: This part can be improved further.\n",
    "#button = 1: RL model + predict via latest model\n",
    "#button = 0: Only predict via latest model\n",
    "button = 1\n",
    "#train_model_from_crash = 1: train model from scratch\n",
    "#train_model_from_crash = 0: reload saved model last time and continue with training.\n",
    "train_model_from_crash = 0\n",
    "main_loop_count = 20\n",
    "epoch_size = 3000\n",
    "steps_for_printing_out_loss = 1000\n",
    "learning_rate = 0.2\n",
    "DQ_ratio = 0.75\n",
    "\n",
    "\n",
    "def Training_model():\n",
    "    \n",
    "    #indicator = 1 means there is an existing model saved\n",
    "    #indicator = 0 means there is no model saved in folder\n",
    "    if os.path.isfile(file_name_model_latest_version):\n",
    "        indicator = 1\n",
    "        input_data = data_input(input_file_path)\n",
    "        score_data = data_input(score_file_path)\n",
    "    else:\n",
    "        indicator = 0\n",
    "        input_data = data_input(input_file_path_initiate)\n",
    "        score_data = data_input(score_file_path_initiate)\n",
    "        #another option: give some initial value manually, for instance:\n",
    "        #input_data = torch.tensor([0,0,0,0,0,0,0,0,0], dtype=torch.float)\n",
    "        #score_data = torch.tensor([0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.11], dtype=torch.float)\n",
    "\n",
    "    input = input_data\n",
    "    target = score_data\n",
    "    net = Net()\n",
    "    # 5 error functions with explainatioins(5 Regression Loss Functions All Machine Learners Should Know): https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "    # HX: It should be alrighht to use MSE instead of MAE, as there is no outlier inside training data here\n",
    "    loss_functioin = nn.MSELoss()\n",
    "    # to explore: visulize parameter updating process, as well as loss impact.\n",
    "    # optim comparation between: SGD & Adam: https://medium.com/@Biboswan98/optim-adam-vs-optim-sgd-lets-dive-in-8dbf1890fbdc\n",
    "    # Here should use Adam compared with SGD(need to explore other Oprim as well), but learning rate should be setup with some strategy. --------Pending\n",
    "    optimizer = optim.SGD(net.parameters(), lr = learning_rate)\n",
    "    # to explore: if indicator == 0, any good start of parameter can be pre-assigned? instead of starting from scratch\n",
    "    if indicator == 1:\n",
    "        state_dict_last_version = torch.load('Model/model_latest_version.pt')['state_dict']\n",
    "        net.load_state_dict(state_dict_last_version)\n",
    "        #to explore function to load optimizer from existing model\n",
    "        #optimizer.load_state_dict(torch.load('model_latest_version.pt')['optimizer'])\n",
    "    #training loop:\n",
    "    for i in range(1,epoch_size + 1):\n",
    "        #to explore: a batch job for training\n",
    "        #to explore: how to save best performance model during 6000 epochs\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        # this is the most important configuration: excludes calculation of loss without real target value\n",
    "        output[target == -2] = -2\n",
    "        output[target == -1.1] = -1.1\n",
    "        # difference between loss, error,criterion: https://datascience.stackexchange.com/questions/10250/what-is-the-difference-between-objective-error-criterion-cost-loss-fun\n",
    "        loss = loss_functioin(output, target)\n",
    "        loss.backward()\n",
    "        if i % (steps_for_printing_out_loss) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss.cpu().detach().numpy()))\n",
    "        # Does the update\n",
    "        optimizer.step()\n",
    "    \n",
    "    if indicator == 1:\n",
    "        copyfile(file_name_model_latest_version, file_name_model_last_version)\n",
    "    else:\n",
    "        torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_last_version)\n",
    "    torch.save({'state_dict': net.state_dict(),'optimizer': optimizer.state_dict()}, file_name_model_latest_version)\n",
    "    \n",
    "    #to export prediction output & target, to review the major difference for optimizing model purpose\n",
    "    # to explore: to visulize this part with real time if possible\n",
    "    export_output = output.clone()\n",
    "    export_output = export_output.cpu().detach().numpy()\n",
    "    np.savetxt('Data/output.csv',export_output,delimiter=',')\n",
    "    export_target = target.clone()\n",
    "    export_target = export_target.cpu().detach().numpy()\n",
    "    np.savetxt('Data/target.csv',export_target,delimiter=',')\n",
    "\n",
    "\n",
    "def RL_model():\n",
    "    tie = 0\n",
    "    win = 0\n",
    "    loss = 0\n",
    "    not_valid_start = 0\n",
    "    # pending for development: to let lastest to play with a same pre-defined version, to measure the performance.\n",
    "    #load model\n",
    "    model_last_version = Net()\n",
    "    state_dict_last_version = torch.load(file_name_model_last_version)['state_dict']\n",
    "    model_last_version.load_state_dict(state_dict_last_version)\n",
    "    \n",
    "    model_latest_version = Net()\n",
    "    state_dict_latest_version = torch.load(file_name_model_latest_version)['state_dict']\n",
    "    model_latest_version.load_state_dict(state_dict_latest_version)\n",
    "    \n",
    "    #load testing data: 82 starting points\n",
    "    training_data = data_input(training_file_path)\n",
    "\n",
    "    #to explore: is that possible to perform prediction below by batch, instead of 1 by 1?\n",
    "    #game starts: between 2 versions\n",
    "    for model_sequence in range(0, 2):\n",
    "        for x in range(0,82):\n",
    "            torch_tensor = training_data[x].clone()\n",
    "            #initial\n",
    "            input_status = []\n",
    "            next_action_taken = []\n",
    "            score = []\n",
    "            for j in range(0,9):\n",
    "                if j == model_sequence:\n",
    "                    ###########another exceptional handling: if input without equal occurance of 1 & -1 - pending for coding\n",
    "                    game_a = game_agent(torch_tensor,0)\n",
    "                    if game_a.verify_result() == True:\n",
    "                        print('not valid input, as game has been over')\n",
    "                        not_valid_start += 1\n",
    "                        break\n",
    "                    elif 0 not in torch_tensor:\n",
    "                        print('input tie & with 9 value')\n",
    "                        not_valid_start += 1\n",
    "                        break\n",
    "\n",
    "                torch_tensor_saved = torch_tensor.clone()\n",
    "                input_status.append(torch_tensor_saved.cpu().numpy())\n",
    "                #predict\n",
    "                #if j % 2 == 1, it means to let last version take the first action\n",
    "                if j % 2 == model_sequence:\n",
    "                    next_vision = model_latest_version(torch_tensor)\n",
    "                else:\n",
    "                    next_vision = model_last_version(torch_tensor)\n",
    "\n",
    "                current_score = torch.ones(9) * -2\n",
    "                #comprehance predict result, via making impossible option as '-1.1'\n",
    "                for k in range(0,9):\n",
    "                    if torch_tensor[k] != 0:\n",
    "                        next_vision[k] = -1.1\n",
    "                        current_score[k] = -1.1\n",
    "                next_step = next_vision.argmax()\n",
    "                #save next action\n",
    "\n",
    "                next_action_taken.append(next_step.cpu().numpy())\n",
    "                score.append(current_score.cpu().numpy())\n",
    "                #generate result\n",
    "                torch_tensor[next_step] = 1\n",
    "                game_a = game_agent(torch_tensor,0)\n",
    "                # varify status of result\n",
    "                # training data duplication should be avoid somewhere, also some inout, action, and different DQ score????????\n",
    "                if game_a.verify_result() == True:\n",
    "                    # print(game_a.verify_result())\n",
    "                    # calculate DQ\n",
    "                    if j % 2 == 0:\n",
    "                        win += 1\n",
    "                    else:\n",
    "                        loss += 1\n",
    "                    # to explore: an enhancement on model, strategy to encourage model for a faster win \n",
    "                    current_final_score = 1\n",
    "                    #update score\n",
    "                    #To explore: DQ learning score enhancement? any alogrithm wise enhancement can be done??\n",
    "                    for k in range(0, len(next_action_taken)):\n",
    "                        score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "                    break\n",
    "                else:\n",
    "                    if 0 not in torch_tensor:\n",
    "                        #print('tie')\n",
    "                        tie = tie + 1\n",
    "                        current_final_score = 0\n",
    "                        #update score\n",
    "                        #To explore: DQ learning score enhancement? any alogrithm wise enhancement can be done??\n",
    "                        for k in range(0, len(next_action_taken)):\n",
    "                            score[-(k+1)][next_action_taken[-(k+1)]] = ((-1 * DQ_ratio)**(k))\n",
    "                        break\n",
    "                    else:\n",
    "                        #generate next input\n",
    "                        torch_tensor *= -1\n",
    "            input_status_df = pd.DataFrame(input_status)\n",
    "            input_status_df.to_csv(input_file_path, index=False, mode='a', header=False)\n",
    "            next_action_taken_df = pd.DataFrame(next_action_taken)\n",
    "            next_action_taken_df.to_csv(next_action_file_path, index=False, mode='a', header=False)\n",
    "            score_df = pd.DataFrame(score)\n",
    "            score_df.to_csv(score_file_path, index=False, mode='a', header=False)\n",
    "    #remove duplication:\n",
    "    input_status_df = pd.read_csv(input_file_path, header = None)\n",
    "    next_action_taken_df = pd.read_csv(next_action_file_path, header = None)\n",
    "    score_df = pd.read_csv(score_file_path, header = None)\n",
    "    consul_df = pd.concat([input_status_df, next_action_taken_df, score_df], axis=1)\n",
    "    consul_df = consul_df.replace(-0.0, 0.0)\n",
    "    consul_df.drop_duplicates(keep = 'first', inplace = True) \n",
    "    input_status_df = consul_df.iloc[:,0:9].copy()\n",
    "    next_action_taken_df = consul_df.iloc[:,9:10].copy()\n",
    "    score_df = consul_df.iloc[:,10:].copy()\n",
    "    input_status_df.to_csv(input_file_path, index=False, header=False)\n",
    "    next_action_taken_df.to_csv(next_action_file_path, index=False, header=False)\n",
    "    score_df.to_csv(score_file_path, index=False, header=False)\n",
    "\n",
    "    print(\"win: \" + str(win))\n",
    "    print(\"Loss: \" + str(loss))\n",
    "    print(\"Tie: \" + str(tie))\n",
    "    print(\"Not valid start: \" + str(not_valid_start))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if train_model_from_crash == 1:\n",
    "        os.remove(file_name_model_latest_version)\n",
    "        os.remove(file_name_model_last_version)\n",
    "        os.remove(input_file_path)\n",
    "        os.remove(score_file_path)\n",
    "        os.remove(next_action_file_path)\n",
    "        \n",
    "    if button == 1:\n",
    "        for loops in range(0, main_loop_count):\n",
    "            Training_model()\n",
    "            RL_model()\n",
    "    else:\n",
    "        RL_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
